{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd1a8e57-70c9-4849-a416-b05244f05bfa",
   "metadata": {},
   "source": [
    "### VAESIM v6\n",
    "\n",
    "1) Build on best performances from sweep\n",
    "2) Introduce temperature scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe72fd53-f5a3-43cd-9688-597871319d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in /home/matteo/anaconda3/envs/pytorch/lib/python3.9/site-packages (0.5.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: opencv-python in /home/matteo/anaconda3/envs/pytorch/lib/python3.9/site-packages (4.5.5.64)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /home/matteo/anaconda3/envs/pytorch/lib/python3.9/site-packages (from opencv-python) (1.21.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchextractor in /home/matteo/anaconda3/envs/pytorch/lib/python3.9/site-packages (0.3.0)\n",
      "Requirement already satisfied: numpy in /home/matteo/anaconda3/envs/pytorch/lib/python3.9/site-packages (from torchextractor) (1.21.5)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/matteo/anaconda3/envs/pytorch/lib/python3.9/site-packages (from torchextractor) (1.11.0)\n",
      "Requirement already satisfied: typing_extensions in /home/matteo/anaconda3/envs/pytorch/lib/python3.9/site-packages (from torch>=1.4.0->torchextractor) (4.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: omegaconf in /home/matteo/anaconda3/envs/pytorch/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /home/matteo/anaconda3/envs/pytorch/lib/python3.9/site-packages (from omegaconf) (6.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /home/matteo/anaconda3/envs/pytorch/lib/python3.9/site-packages (from omegaconf) (4.9.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install imutils\n",
    "%pip install opencv-python\n",
    "%pip install torchextractor\n",
    "%pip install omegaconf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be80327b-e561-451d-b5de-d1fb67c7e937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/Unsupervised/vaesim_baselines/VAESIM/../../NeuroGEN_Pytorch/utils/utils.py:134: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  warnings.warn(\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmatteoferrante\u001b[0m (\u001b[33mtorvergatafmri\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../NeuroGEN_Pytorch/\")\n",
    "import torch\n",
    "import torch.distributions as D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "from classes.Architectures import VAEDecoder, VAEEncoder, Discriminator,cVAEDecoder\n",
    "from classes.Cluster import VAESIM\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import MNIST,CIFAR10\n",
    "from torchvision.transforms import Compose,ToTensor,Resize,PILToTensor\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from torch import distributions as D\n",
    "from torch.nn.functional import softmax\n",
    "import wandb\n",
    "\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from utils.callbacks import *\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from utils.utils import linear_assignment\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import os\n",
    "import seaborn as sns\n",
    "#from coclust.evaluation.external import accuracy\n",
    "import pandas as pd\n",
    "wandb.login()\n",
    "from evaluations import *\n",
    "\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6687776-226f-4519-b714-206cc36475f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,latent_dim=50,n_conv=3,n_init_filters=32,input_channels=1):\n",
    "        super().__init__()\n",
    "        layers=[]\n",
    "        for i in range(n_conv):\n",
    "            if i==0:\n",
    "                layers.append(nn.Conv2d(input_channels,n_init_filters,kernel_size=4,stride=2,padding=1))\n",
    "                layers.append(nn.ReLU())\n",
    "                layers.append(nn.BatchNorm2d(n_init_filters))\n",
    "            else:\n",
    "                layers.append(nn.Conv2d(n_init_filters*(2**(i-1)),n_init_filters*2**i,kernel_size=4,stride=2,padding=1))\n",
    "                layers.append(nn.ReLU())\n",
    "                layers.append(nn.BatchNorm2d(n_init_filters*2**i))\n",
    "        layers.append(nn.Flatten())\n",
    "        layers.append(nn.LazyLinear(latent_dim))\n",
    "        \n",
    "        self.network=nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.network(x)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b321274-f756-4890-8610-1d825b29aee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel_size,stride=2,padding=1,separable=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.out_channels=out_channels\n",
    "        \n",
    "        if separable:\n",
    "            self.conv=DepthSepConv2d(in_channels,out_channels,kernel_size=kernel_size,stride=stride,padding=padding)\n",
    "        else:\n",
    "            self.conv=nn.Conv2d(in_channels,out_channels,kernel_size=kernel_size,stride=stride,padding=padding)\n",
    "        self.norm=nn.BatchNorm2d(out_channels)\n",
    "        self.act = nn.GELU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.act(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "class ConvTransposeBlock(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel_size,stride=2,padding=1,separable=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_channels=in_channels\n",
    "        self.out_channels=out_channels\n",
    "        if separable:\n",
    "            self.conv=DepthSepConvTranspose2d(in_channels,out_channels,kernel_size=kernel_size,stride=stride,padding=padding)\n",
    "        else:\n",
    "            self.conv=nn.ConvTranspose2d(in_channels,out_channels,kernel_size=kernel_size,stride=stride,padding=padding)\n",
    "        self.norm=nn.BatchNorm2d(out_channels)\n",
    "        self.act = nn.GELU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.act(x)\n",
    "        \n",
    "        return x\n",
    "            \n",
    "\n",
    "class decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim=50,target_shape=(1,28,28) , n_conv=2, n_init_filters=64, condition_dim=10):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.condition_dim=condition_dim\n",
    "\n",
    "\n",
    "\n",
    "        # infer the starting dimension.\n",
    "        target_shape_side = target_shape[-1]\n",
    "\n",
    "\n",
    "\n",
    "        self.startDim = target_shape_side // (2 ** n_conv)\n",
    "\n",
    "        self.n_init_filters=n_init_filters\n",
    "        \n",
    "        #self.predecoder=nn.Unflatten(self.first_channels*self.startDim*self.startDim)\n",
    "        self.predecoder=nn.Linear(latent_dim,self.n_init_filters*self.startDim*self.startDim)\n",
    "        self.unflatten=nn.Unflatten(1,(self.n_init_filters,self.startDim,self.startDim))\n",
    "\n",
    "        self.condition =  nn.Linear(self.condition_dim,self.startDim*self.startDim)\n",
    "        self.condition2shape = nn.Unflatten(1, (1,self.startDim , self.startDim))\n",
    "        feature_layers = []\n",
    "        for i in range(n_conv):\n",
    "            if i==0:\n",
    "                feature_layers.append(nn.LazyConvTranspose2d(n_init_filters,kernel_size=4,stride=2,padding=1))\n",
    "            else:\n",
    "                feature_layers.append(nn.ConvTranspose2d(n_init_filters*(2**(i-1)),n_init_filters*2**i,kernel_size=4,stride=2,padding=1))\n",
    "\n",
    "        self.features = nn.Sequential(*feature_layers)\n",
    "\n",
    "        self.decoder_output=nn.LazyConvTranspose2d(target_shape[0],3,padding=1)\n",
    "        self.activation=nn.Sigmoid()\n",
    "\n",
    "    def forward(self,x,c):\n",
    "        x = self.predecoder(x)\n",
    "        x= self.unflatten(x)\n",
    "\n",
    "        c= self.condition(c)\n",
    "        c= self.condition2shape(c)\n",
    "        \n",
    "        x= torch.concat((x,c),axis=1)\n",
    "        x = x.view(x.shape[0], -1, self.startDim, self.startDim)\n",
    "        x = self.features(x)\n",
    "        x = self.decoder_output(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    \n",
    "## CONDITIONAL DECODER\n",
    "class cDecoder(nn.Module):\n",
    "    def __init__(self,latent_dim,conv_filters,target_dim=(1,32,32),init_channels=1,kernel_size=4,first_channels=32,condition_dim=10):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.startDim=int(target_dim[-1]/2**(len(conv_filters)))\n",
    "        self.condition_dim=condition_dim\n",
    "        \n",
    "        l=len(conv_filters)\n",
    "        conv=[]\n",
    "        conv_filters=[first_channels+1]+conv_filters\n",
    "        \n",
    "        \n",
    "        self.predecoder=nn.Linear(latent_dim,first_channels*self.startDim*self.startDim)\n",
    "        self.unflatten=nn.Unflatten(1,(first_channels,self.startDim,self.startDim))\n",
    "        \n",
    "        self.condition =  nn.Linear(self.condition_dim,self.startDim*self.startDim)\n",
    "        self.condition2shape = nn.Unflatten(1, (1,self.startDim , self.startDim))\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(l):\n",
    "            conv.append(ConvTransposeBlock(conv_filters[i],conv_filters[i+1],kernel_size))\n",
    "        \n",
    "        self.decoder_output=nn.LazyConvTranspose2d(init_channels,kernel_size=3,padding=1)\n",
    "        self.activation=nn.Sigmoid()\n",
    "        \n",
    "        self.features=nn.Sequential(*conv)\n",
    "                        \n",
    "    def forward(self,x,c):\n",
    "        \n",
    "        x = self.predecoder(x)\n",
    "        x= self.unflatten(x)\n",
    "\n",
    "        c= self.condition(c)\n",
    "        c= self.condition2shape(c)\n",
    "\n",
    "        x= torch.concat((x,c),axis=1)\n",
    "        \n",
    "        x= self.features(x)\n",
    "        x = self.decoder_output(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2643b18d-3ab0-405b-b8a7-2a181cf0b9de",
   "metadata": {},
   "source": [
    "#### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb3a8f9d-324f-487d-a300-1f351764565e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running model with KL: True, similarity loss: True and sampling: False temperature: 5 reinitilize: 0.0 ema: 0.95 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/matteo/Unsupervised/vaesim_baselines/VAESIM/wandb/run-20220813_000957-3pp2fok3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/torvergatafmri/NeuroGEN_Pytorch/runs/3pp2fok3\" target=\"_blank\">chocolate-paper-27</a></strong> to <a href=\"https://wandb.ai/torvergatafmri/NeuroGEN_Pytorch\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/torvergatafmri/NeuroGEN_Pytorch/runs/3pp2fok3?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fd5178df9a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_basis=40\n",
    "latent_dim=32\n",
    "input_dim=(1,32,32)\n",
    "\n",
    "sample_cluster=False\n",
    "kl_weight=5e-3\n",
    "sim_weight=0.1\n",
    "similarity=True\n",
    "kl=True\n",
    "reinit=0.\n",
    "\n",
    "temperature=5\n",
    "\n",
    "## using VAEEncoder\n",
    "encoder_architecture=[(0,128),(0,256),(0,384)]\n",
    "decoder_architecture=[(0,384),(0,256),(0,128)]\n",
    "\n",
    "\n",
    "e=VAEEncoder( latent_dim=latent_dim,  conv_layer_list=encoder_architecture)\n",
    "d=cDecoder(latent_dim,[384,256,128],condition_dim=n_basis)\n",
    "\n",
    "\n",
    "model=VAESIM(input_dim=input_dim,latent_dim=latent_dim,encoder=e,decoder=d,n_basis=n_basis,weight=kl_weight,sim_weight=sim_weight,similarity=similarity,kl=kl,sample_cluster=sample_cluster,reinit=reinit,temperature=temperature,schedule=True,ema=0.95)\n",
    "\n",
    "\n",
    "EPOCHS=60\n",
    "BS=2000\n",
    "INIT_LR=1e-4\n",
    "\n",
    "config={\"dataset\":\"MNIST10\", \"type\":\"VAESIM\",\"latent_dim\":latent_dim, \"n_basis\":n_basis, \"input_dim\":input_dim}\n",
    "config[\"epochs\"]=EPOCHS\n",
    "config[\"BS\"]=BS\n",
    "config[\"init_lr\"]=INIT_LR\n",
    "\n",
    "config[\"sample_cluster\"]=sample_cluster\n",
    "config[\"use_kl_loss\"]=kl\n",
    "config[\"use_similarity_loss\"]=similarity\n",
    "config[\"reinitialization_probability\"]=reinit\n",
    "config[\"kl_weight\"]=kl_weight\n",
    "config[\"sim_weight\"]=sim_weight\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "wandb.init(project=\"NeuroGEN_Pytorch\",config=config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "440aa8b2-3ccd-4fe1-bc37-e44d0bf36a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f5d1bc-604f-4f92-abe3-44e250582c12",
   "metadata": {},
   "source": [
    "## Run this cell to Init the basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d463388-e245-4c2c-85a3-da6b9a3c266d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing t-SNE to visualize from 32 to 2 dim - this could take a while..\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=torch.rand(BS,*input_dim).to(device)\n",
    "z_mean,z_log_var=model.encoder(x)\n",
    "q_z = D.normal.Normal(z_mean, torch.exp(0.5 * z_log_var))\n",
    "z=q_z.rsample()\n",
    "\n",
    "model.init_basis(z.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e61d8df1-d093-431e-baa2-8081bf25e870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 128, 16, 16]           2,176\n",
      "      ConvResBlock-2          [-1, 128, 16, 16]               0\n",
      "            Conv2d-3            [-1, 256, 8, 8]         524,544\n",
      "      ConvResBlock-4            [-1, 256, 8, 8]               0\n",
      "            Conv2d-5            [-1, 384, 4, 4]       1,573,248\n",
      "      ConvResBlock-6            [-1, 384, 4, 4]               0\n",
      "           Flatten-7                 [-1, 6144]               0\n",
      "            Linear-8                   [-1, 32]         196,640\n",
      "            Linear-9                   [-1, 32]         196,640\n",
      "       VAEEncoder-10       [[-1, 32], [-1, 32]]               0\n",
      "           Linear-11                  [-1, 512]          16,896\n",
      "        Unflatten-12             [-1, 32, 4, 4]               0\n",
      "           Linear-13                   [-1, 16]             656\n",
      "        Unflatten-14              [-1, 1, 4, 4]               0\n",
      "  ConvTranspose2d-15            [-1, 384, 8, 8]         203,136\n",
      "      BatchNorm2d-16            [-1, 384, 8, 8]             768\n",
      "             GELU-17            [-1, 384, 8, 8]               0\n",
      "ConvTransposeBlock-18            [-1, 384, 8, 8]               0\n",
      "  ConvTranspose2d-19          [-1, 256, 16, 16]       1,573,120\n",
      "      BatchNorm2d-20          [-1, 256, 16, 16]             512\n",
      "             GELU-21          [-1, 256, 16, 16]               0\n",
      "ConvTransposeBlock-22          [-1, 256, 16, 16]               0\n",
      "  ConvTranspose2d-23          [-1, 128, 32, 32]         524,416\n",
      "      BatchNorm2d-24          [-1, 128, 32, 32]             256\n",
      "             GELU-25          [-1, 128, 32, 32]               0\n",
      "ConvTransposeBlock-26          [-1, 128, 32, 32]               0\n",
      "  ConvTranspose2d-27            [-1, 1, 32, 32]           1,153\n",
      "          Sigmoid-28            [-1, 1, 32, 32]               0\n",
      "         cDecoder-29            [-1, 1, 32, 32]               0\n",
      "================================================================\n",
      "Total params: 4,814,161\n",
      "Trainable params: 4,814,161\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 7.66\n",
      "Params size (MB): 18.36\n",
      "Estimated Total Size (MB): 26.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f947852-015f-4410-b7ad-b8abcbc9cda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/matteo/.medmnist/pneumoniamnist.npz\n",
      "Using downloaded and verified file: /home/matteo/.medmnist/pneumoniamnist.npz\n",
      "Using downloaded and verified file: /home/matteo/.medmnist/pneumoniamnist.npz\n"
     ]
    }
   ],
   "source": [
    "transform=Compose([Resize(32),ToTensor()])\n",
    "\n",
    "data_flag = 'pneumoniamnist'\n",
    "# data_flag = 'breastmnist'\n",
    "download = True\n",
    "\n",
    "\n",
    "info = INFO[data_flag]\n",
    "task = info['task']\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "#train_dataloader=DataLoader(train_dataset,batch_size=BS,shuffle=True)\n",
    "#test_dataloader=DataLoader(test_dataset,batch_size=BS,shuffle=False)\n",
    "\n",
    "train_dataset = DataClass(split='train', transform=transform, download=download)\n",
    "val_dataset = DataClass(split='val', transform=transform, download=download)\n",
    "test_dataset = DataClass(split='test', transform=transform, download=download)\n",
    "testval_dataset=val_dataset+test_dataset\n",
    "\n",
    "\n",
    "train_dataloader=DataLoader(train_dataset,batch_size=BS,shuffle=True)\n",
    "val_dataloader=DataLoader(val_dataset,batch_size=BS,shuffle=True)\n",
    "\n",
    "test_dataloader=DataLoader(testval_dataset,batch_size=BS,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31badca1-2e5f-4dfa-bdda-c10aa7b6ad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path=\"models/vaesim_pneumonia\"\n",
    "os.makedirs(base_path,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bb1426-6388-425f-81e5-91b8b585e185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90c4a121-c950-4f92-bd49-757153926aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|█| 3/3 [00:01<00:00,  2.83batch/s, loss=0.176, sim_loss=0.0296, recon_loss=0.146, kl_loss\n",
      "/home/matteo/Unsupervised/vaesim_baselines/VAESIM/../../NeuroGEN_Pytorch/utils/callbacks.py:158: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  c=torch.nn.functional.softmax(logprobs/0.25)\n",
      "Epoch 1: 100%|█| 3/3 [00:01<00:00,  2.86batch/s, loss=0.557, sim_loss=0.446, recon_loss=0.105, kl_loss=\n",
      "Epoch 2: 100%|█| 3/3 [00:01<00:00,  2.87batch/s, loss=0.541, sim_loss=0.466, recon_loss=0.0633, kl_loss\n",
      "Epoch 3: 100%|█| 3/3 [00:01<00:00,  2.90batch/s, loss=0.506, sim_loss=0.449, recon_loss=0.0479, kl_loss\n",
      "Epoch 4: 100%|█| 3/3 [00:01<00:00,  2.86batch/s, loss=0.461, sim_loss=0.414, recon_loss=0.0378, kl_loss\n",
      "Epoch 5: 100%|█| 3/3 [00:01<00:00,  2.91batch/s, loss=0.39, sim_loss=0.345, recon_loss=0.0348, kl_loss=\n",
      "Epoch 6: 100%|█| 3/3 [00:00<00:00,  3.16batch/s, loss=0.271, sim_loss=0.232, recon_loss=0.0287, kl_loss\n",
      "Epoch 7: 100%|█| 3/3 [00:00<00:00,  3.15batch/s, loss=0.216, sim_loss=0.18, recon_loss=0.0276, kl_loss=\n",
      "Epoch 8: 100%|█| 3/3 [00:00<00:00,  3.23batch/s, loss=0.21, sim_loss=0.177, recon_loss=0.0247, kl_loss=\n",
      "Epoch 9: 100%|█| 3/3 [00:01<00:00,  2.85batch/s, loss=0.184, sim_loss=0.153, recon_loss=0.0227, kl_loss\n",
      "Epoch 10: 100%|█| 3/3 [00:01<00:00,  2.89batch/s, loss=0.175, sim_loss=0.146, recon_loss=0.0209, kl_los\n",
      "Epoch 11: 100%|█| 3/3 [00:01<00:00,  2.89batch/s, loss=0.171, sim_loss=0.143, recon_loss=0.0199, kl_los\n",
      "Epoch 12: 100%|█| 3/3 [00:01<00:00,  2.89batch/s, loss=0.123, sim_loss=0.0968, recon_loss=0.0187, kl_lo\n",
      "Epoch 13: 100%|█| 3/3 [00:01<00:00,  2.95batch/s, loss=0.113, sim_loss=0.0872, recon_loss=0.0188, kl_lo\n",
      "Epoch 14: 100%|█| 3/3 [00:01<00:00,  2.98batch/s, loss=0.0894, sim_loss=0.0647, recon_loss=0.018, kl_lo\n",
      "Epoch 15: 100%|█| 3/3 [00:01<00:00,  2.94batch/s, loss=0.0804, sim_loss=0.057, recon_loss=0.0167, kl_lo\n",
      "Epoch 16: 100%|█| 3/3 [00:01<00:00,  2.89batch/s, loss=0.0673, sim_loss=0.044, recon_loss=0.0168, kl_lo\n",
      "Epoch 17: 100%|█| 3/3 [00:01<00:00,  2.82batch/s, loss=0.0584, sim_loss=0.0353, recon_loss=0.017, kl_lo\n",
      "Epoch 18: 100%|█| 3/3 [00:01<00:00,  2.91batch/s, loss=0.0587, sim_loss=0.0359, recon_loss=0.0167, kl_l\n",
      "Epoch 19: 100%|█| 3/3 [00:01<00:00,  2.91batch/s, loss=0.0597, sim_loss=0.0377, recon_loss=0.0163, kl_l\n",
      "Epoch 20: 100%|█| 3/3 [00:01<00:00,  2.91batch/s, loss=0.057, sim_loss=0.0358, recon_loss=0.0154, kl_lo\n",
      "Epoch 21: 100%|█| 3/3 [00:01<00:00,  2.94batch/s, loss=0.0539, sim_loss=0.0327, recon_loss=0.0155, kl_l\n",
      "Epoch 22: 100%|█| 3/3 [00:00<00:00,  3.19batch/s, loss=0.059, sim_loss=0.0377, recon_loss=0.0155, kl_lo\n",
      "Epoch 23: 100%|█| 3/3 [00:01<00:00,  2.94batch/s, loss=0.0605, sim_loss=0.0391, recon_loss=0.0157, kl_l\n",
      "Epoch 24: 100%|█| 3/3 [00:00<00:00,  3.10batch/s, loss=0.0634, sim_loss=0.0426, recon_loss=0.0151, kl_l\n",
      "Epoch 25: 100%|█| 3/3 [00:00<00:00,  3.23batch/s, loss=0.0583, sim_loss=0.0371, recon_loss=0.0156, kl_l\n",
      "Epoch 26: 100%|█| 3/3 [00:00<00:00,  3.25batch/s, loss=0.0635, sim_loss=0.0424, recon_loss=0.0155, kl_l\n",
      "Epoch 27: 100%|█| 3/3 [00:01<00:00,  2.87batch/s, loss=0.0622, sim_loss=0.0417, recon_loss=0.0147, kl_l\n",
      "Epoch 28: 100%|█| 3/3 [00:01<00:00,  2.90batch/s, loss=0.0611, sim_loss=0.0406, recon_loss=0.0149, kl_l\n",
      "Epoch 29: 100%|█| 3/3 [00:01<00:00,  2.90batch/s, loss=0.0605, sim_loss=0.0403, recon_loss=0.0146, kl_l\n",
      "Epoch 30: 100%|█| 3/3 [00:01<00:00,  2.90batch/s, loss=0.062, sim_loss=0.0415, recon_loss=0.0151, kl_lo\n",
      "Epoch 31: 100%|█| 3/3 [00:01<00:00,  2.88batch/s, loss=0.0566, sim_loss=0.0366, recon_loss=0.0145, kl_l\n",
      "Epoch 32: 100%|█| 3/3 [00:01<00:00,  2.98batch/s, loss=0.0564, sim_loss=0.0364, recon_loss=0.0147, kl_l\n",
      "Epoch 33: 100%|█| 3/3 [00:01<00:00,  2.93batch/s, loss=0.0527, sim_loss=0.0327, recon_loss=0.0145, kl_l\n",
      "Epoch 34: 100%|█| 3/3 [00:01<00:00,  2.47batch/s, loss=0.06, sim_loss=0.0402, recon_loss=0.0142, kl_los\n",
      "Epoch 35: 100%|█| 3/3 [00:01<00:00,  2.83batch/s, loss=0.0586, sim_loss=0.0387, recon_loss=0.0144, kl_l\n",
      "Epoch 36: 100%|█| 3/3 [00:01<00:00,  2.90batch/s, loss=0.0567, sim_loss=0.037, recon_loss=0.0143, kl_lo\n",
      "Epoch 37: 100%|█| 3/3 [00:01<00:00,  2.83batch/s, loss=0.0603, sim_loss=0.0409, recon_loss=0.014, kl_lo\n",
      "Epoch 38: 100%|█| 3/3 [00:01<00:00,  2.88batch/s, loss=0.0558, sim_loss=0.0365, recon_loss=0.0138, kl_l\n",
      "Epoch 39: 100%|█| 3/3 [00:01<00:00,  2.94batch/s, loss=0.0528, sim_loss=0.0336, recon_loss=0.0138, kl_l\n",
      "Epoch 40: 100%|█| 3/3 [00:00<00:00,  3.24batch/s, loss=0.0561, sim_loss=0.0369, recon_loss=0.014, kl_lo\n",
      "Epoch 41: 100%|█| 3/3 [00:00<00:00,  3.19batch/s, loss=0.0521, sim_loss=0.0327, recon_loss=0.0141, kl_l\n",
      "Epoch 42: 100%|█| 3/3 [00:00<00:00,  3.24batch/s, loss=0.0587, sim_loss=0.0392, recon_loss=0.0143, kl_l\n",
      "Epoch 43: 100%|█| 3/3 [00:00<00:00,  3.27batch/s, loss=0.0594, sim_loss=0.0404, recon_loss=0.0137, kl_l\n",
      "Epoch 44: 100%|█| 3/3 [00:00<00:00,  3.13batch/s, loss=0.0582, sim_loss=0.0388, recon_loss=0.014, kl_lo\n",
      "Epoch 45: 100%|█| 3/3 [00:01<00:00,  2.91batch/s, loss=0.0536, sim_loss=0.0343, recon_loss=0.0139, kl_l\n",
      "Epoch 46: 100%|█| 3/3 [00:00<00:00,  3.12batch/s, loss=0.0603, sim_loss=0.0409, recon_loss=0.0141, kl_l\n",
      "Epoch 47: 100%|█| 3/3 [00:00<00:00,  3.17batch/s, loss=0.057, sim_loss=0.0379, recon_loss=0.0139, kl_lo\n",
      "Epoch 48: 100%|█| 3/3 [00:00<00:00,  3.10batch/s, loss=0.0588, sim_loss=0.0396, recon_loss=0.0141, kl_l\n",
      "Epoch 49: 100%|█| 3/3 [00:00<00:00,  3.19batch/s, loss=0.0634, sim_loss=0.0445, recon_loss=0.0137, kl_l\n",
      "Epoch 50: 100%|█| 3/3 [00:00<00:00,  3.14batch/s, loss=0.0644, sim_loss=0.0454, recon_loss=0.0138, kl_l\n",
      "Epoch 51: 100%|█| 3/3 [00:00<00:00,  3.19batch/s, loss=0.0574, sim_loss=0.0385, recon_loss=0.0136, kl_l\n",
      "Epoch 52: 100%|█| 3/3 [00:00<00:00,  3.10batch/s, loss=0.0678, sim_loss=0.0486, recon_loss=0.014, kl_lo\n",
      "Epoch 53: 100%|█| 3/3 [00:01<00:00,  2.80batch/s, loss=0.0637, sim_loss=0.045, recon_loss=0.0135, kl_lo\n",
      "Epoch 54: 100%|█| 3/3 [00:01<00:00,  2.88batch/s, loss=0.0667, sim_loss=0.0476, recon_loss=0.0139, kl_l\n",
      "Epoch 55: 100%|█| 3/3 [00:01<00:00,  2.89batch/s, loss=0.0603, sim_loss=0.0414, recon_loss=0.0136, kl_l\n",
      "Epoch 56: 100%|█| 3/3 [00:01<00:00,  2.91batch/s, loss=0.0584, sim_loss=0.0392, recon_loss=0.014, kl_lo\n",
      "Epoch 57: 100%|█| 3/3 [00:00<00:00,  3.09batch/s, loss=0.0617, sim_loss=0.0428, recon_loss=0.0135, kl_l\n",
      "Epoch 58: 100%|█| 3/3 [00:00<00:00,  3.19batch/s, loss=0.0621, sim_loss=0.043, recon_loss=0.0139, kl_lo\n",
      "Epoch 59: 100%|█| 3/3 [00:00<00:00,  3.14batch/s, loss=0.062, sim_loss=0.043, recon_loss=0.0139, kl_los\n"
     ]
    }
   ],
   "source": [
    "train=True\n",
    "if train:\n",
    "    optimizer=torch.optim.Adam(model.parameters(),lr=INIT_LR)\n",
    "    #optimizer=torch.optim.SGD(model.parameters(),lr=INIT_LR,momentum=0.9)\n",
    "    scheduler=torch.optim.lr_scheduler.StepLR(optimizer,step_size=20,gamma=0.2)\n",
    "\n",
    "    loss_history,recon_loss_history,kl_loss_history,sim_loss_history=model.fit(train_dataloader=train_dataloader,val_dataloader=test_dataloader,epochs=EPOCHS,optimizer=optimizer,device=device,wandb_log=False,save_model=base_path,early_stop=10,scheduler=scheduler)\n",
    "\n",
    "else:\n",
    "    model.load_state_dict(torch.load(\"models/vaesim_mnist/model.pt\"))\n",
    "    model.basis=torch.load(\"models/vaesim_mnist/vaesim_basis.pt\")\n",
    "    model=model.to(device)\n",
    "    model.device=device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04324ac8-1d11-4309-88e7-2a604cea3431",
   "metadata": {},
   "source": [
    "### Baseline Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b1c2c38-b82a-4575-bb0b-58825def899f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  6.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.29it/s]\n"
     ]
    }
   ],
   "source": [
    "cl_train=[]\n",
    "y_train=[]\n",
    "z_train=[]\n",
    "\n",
    "\n",
    "cl_test=[]\n",
    "y_test=[]\n",
    "z_test=[]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x,y in tqdm.tqdm(train_dataloader):\n",
    "        x=x.to(device)\n",
    "        z_mu,z_sigma=model.encoder(x)\n",
    "        dist=D.normal.Normal(z_mu, torch.exp(0.5 * z_sigma))\n",
    "        z=dist.sample()\n",
    "        sim=model.compute_similarity(z)\n",
    "        soft_sim=softmax(sim,dim=1)\n",
    "        cl_train.append(soft_sim.argmax(dim=1).cpu().numpy())\n",
    "        z_train.append(z.cpu().numpy())\n",
    "        y_train.append(y.cpu().numpy())\n",
    "        \n",
    "    for x,y in tqdm.tqdm(test_dataloader):\n",
    "        x=x.to(device)\n",
    "        z_mu,z_sigma=model.encoder(x)\n",
    "        dist=D.normal.Normal(z_mu, torch.exp(0.5 * z_sigma))\n",
    "        z=dist.sample().cpu()\n",
    "        sim=model.compute_similarity(z)\n",
    "        soft_sim=softmax(sim,dim=1)\n",
    "        cl_test.append(soft_sim.argmax(dim=1).cpu().numpy())\n",
    "        \n",
    "        z_test.append(z.cpu().numpy())\n",
    "        y_test.append(y.cpu().numpy())\n",
    "        \n",
    "    cl_train=np.concatenate(cl_train,0)\n",
    "    z_train=np.concatenate(z_train,0)\n",
    "    y_train=np.concatenate(y_train,0)\n",
    "\n",
    "    cl_test=np.concatenate(cl_test,0)\n",
    "    z_test=np.concatenate(z_test,0)\n",
    "    y_test=np.concatenate(y_test,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b471093-8a01-4884-b64b-641d29779c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3pp2fok3) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='21.431 MB of 21.431 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">chocolate-paper-27</strong>: <a href=\"https://wandb.ai/torvergatafmri/NeuroGEN_Pytorch/runs/3pp2fok3\" target=\"_blank\">https://wandb.ai/torvergatafmri/NeuroGEN_Pytorch/runs/3pp2fok3</a><br/>Synced 6 W&B file(s), 180 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220813_000957-3pp2fok3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3pp2fok3). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/matteo/Unsupervised/vaesim_baselines/VAESIM/wandb/run-20220813_001128-2cakquqr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/torvergatafmri/VAESIM_CHARACT/runs/2cakquqr\" target=\"_blank\">ancient-armadillo-95</a></strong> to <a href=\"https://wandb.ai/torvergatafmri/VAESIM_CHARACT\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/torvergatafmri/VAESIM_CHARACT/runs/2cakquqr?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fd5ba02f100>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"name\":\"VAESIM\",\"dataset\":\"pneumonia\",\"n_cluster\":40}\n",
    "wandb.init(project=\"VAESIM_CHARACT\",config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a051980-6724-4e33-8a35-58cbd8ed2099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compute mappings and stat accuracy\n",
      "[WARNING] cluster 1 matched no classes. It's now linked to the mode of the labels. This could lead to decrease in metrics.\n",
      "[WARNING] cluster 4 matched no classes. It's now linked to the mode of the labels. This could lead to decrease in metrics.\n",
      "[WARNING] cluster 11 matched no classes. It's now linked to the mode of the labels. This could lead to decrease in metrics.\n",
      "[WARNING] cluster 17 matched no classes. It's now linked to the mode of the labels. This could lead to decrease in metrics.\n",
      "[WARNING] cluster 19 matched no classes. It's now linked to the mode of the labels. This could lead to decrease in metrics.\n",
      "[WARNING] cluster 23 matched no classes. It's now linked to the mode of the labels. This could lead to decrease in metrics.\n",
      "[WARNING] cluster 25 matched no classes. It's now linked to the mode of the labels. This could lead to decrease in metrics.\n",
      "[WARNING] cluster 27 matched no classes. It's now linked to the mode of the labels. This could lead to decrease in metrics.\n",
      "[WARNING] cluster 28 matched no classes. It's now linked to the mode of the labels. This could lead to decrease in metrics.\n",
      "[WARNING] cluster 29 matched no classes. It's now linked to the mode of the labels. This could lead to decrease in metrics.\n",
      "[WARNING] cluster 30 matched no classes. It's now linked to the mode of the labels. This could lead to decrease in metrics.\n",
      "[WARNING] cluster 38 matched no classes. It's now linked to the mode of the labels. This could lead to decrease in metrics.\n",
      "[WARNING] cluster 39 matched no classes. It's now linked to the mode of the labels. This could lead to decrease in metrics.\n",
      "{0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 0, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1, 21: 1, 22: 1, 23: 1, 24: 1, 25: 1, 26: 1, 27: 1, 28: 1, 29: 1, 30: 1, 31: 1, 32: 1, 33: 1, 34: 1, 35: 1, 36: 1, 37: 1, 38: 1, 39: 1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.00      0.01       369\n",
      "           1       0.68      1.00      0.81       779\n",
      "\n",
      "    accuracy                           0.68      1148\n",
      "   macro avg       0.59      0.50      0.41      1148\n",
      "weighted avg       0.62      0.68      0.55      1148\n",
      "\n",
      "[INFO] compute kNN accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:200: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/matteo/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.44      0.51       369\n",
      "           1       0.77      0.87      0.81       779\n",
      "\n",
      "    accuracy                           0.73      1148\n",
      "   macro avg       0.69      0.65      0.66      1148\n",
      "weighted avg       0.72      0.73      0.72      1148\n",
      "\n",
      "[INFO] compute linear accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LINEAR] epoch 9 loss: 0.9694712162017822 acc: 0.6699999570846558: 100%|█| 10/10 [00:00<00:00, 27.57it/\n",
      "/home/matteo/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/matteo/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/matteo/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/matteo/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/matteo/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/matteo/anaconda3/envs/pytorch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.07      0.13       369\n",
      "           1       0.69      0.95      0.80       779\n",
      "           2       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.67      1148\n",
      "   macro avg       0.14      0.11      0.10      1148\n",
      "weighted avg       0.64      0.67      0.58      1148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs=model_evaluation(z_train,y_train,z_test,y_test,cl_train,cl_test,device=\"cuda\",n_cluster=40,neighbours=10)\n",
    "wandb.log(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfd0d042-6930-4b79-9833-ef05a82754b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch=next(iter(test_dataloader))\n",
    "\n",
    "# model.evaluate(batch,train_dataloader,test_dataloader,wandb_log=True,n_semi=6,lin_epochs=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0606a909-f896-4e45-b667-a78ffde4e25b",
   "metadata": {},
   "source": [
    "## FINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "800a79b5-0836-40a4-8dca-a8296782cad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(loss_history,label=\"loss\")\n",
    "# plt.plot(recon_loss_history,label=\"recon_loss\")\n",
    "# plt.plot(kl_loss_history,label=\"kl_loss\")\n",
    "# plt.plot(sim_loss_history,label=\"sim_loss\")\n",
    "\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4522f3e-d718-475b-a5d0-34362621d8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for x,y in test_dataloader:\n",
    "#     x2,z,s=model(x.to(device))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac8c9c6a-913f-4a9f-9383-52d82efb13f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.basis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd10fea1-df53-4187-b51b-c5958cf03138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,axs=plt.subplots(2,20,figsize=(15,2))\n",
    "\n",
    "# for i in range(20):\n",
    "#     axs[0,i].imshow(x[i].permute(1,2,0))\n",
    "#     axs[1,i].imshow(x2[i].detach().permute(1,2,0).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96549a8-b283-49aa-b558-1b01e25ba2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
